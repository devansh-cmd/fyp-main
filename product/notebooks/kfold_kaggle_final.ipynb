{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Kaggle K-Fold Final Execution\n",
                "This notebook runs the remaining experiments for the Audio Classification project.\n",
                "\n",
                "**Targets:**\n",
                "1. **ESC-50**: HybridNet (5 Folds) - *ResNet/MobileNet already done*\n",
                "2. **EmoDB**: All Models (15 Runs) - *Fresh start*\n",
                "\n",
                "**Prerequisites:**\n",
                "- Dataset: `colab_all_kfold.zip` uploaded as input."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import shutil\n",
                "import zipfile\n",
                "from pathlib import Path\n",
                "import sys\n",
                "import subprocess\n",
                "\n",
                "# --- CONFIG ---\n",
                "KAGGLE_INPUT_DIR = Path('/kaggle/input')\n",
                "WORK_DIR = Path('/kaggle/working/PROJECT')\n",
                "WIN_PREFIX = r'C:\\FYP\\PROJECT'\n",
                "\n",
                "# Clean Workspace\n",
                "if WORK_DIR.exists():\n",
                "    shutil.rmtree(WORK_DIR)\n",
                "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# --- 1. EXTRACT DATA ---\n",
                "# Strategy 1: Look for ZIP\n",
                "zips = list(KAGGLE_INPUT_DIR.glob('**/*.zip'))\n",
                "\n",
                "if zips:\n",
                "    ZIP_PATH = zips[0]\n",
                "    print(f\"Found zip: {ZIP_PATH}\")\n",
                "    print(\"Extracting zip... (this takes ~1-2 mins)\")\n",
                "    with zipfile.ZipFile(ZIP_PATH, 'r') as zf:\n",
                "        zf.extractall('/kaggle/working/')\n",
                "    print(\"Extraction complete.\")\n",
                "else:\n",
                "    # Strategy 2: Look for Unzipped Folder (Kaggle sometimes auto-unzips)\n",
                "    print(\"No zip found. Searching for unzipped 'product' folder...\")\n",
                "    found_product = list(KAGGLE_INPUT_DIR.glob('**/product'))\n",
                "    \n",
                "    if found_product:\n",
                "        # product folder found, usually in /kaggle/input/datasetname/PROJECT/product\n",
                "        # We need the PARENT of 'product' (which corresponds to 'PROJECT')\n",
                "        # Actually, let's just copy everything from the dataset root to working\n",
                "        # But we need to be careful to get the structure C:\\FYP\\PROJECT... mapping right\n",
                "        \n",
                "        # Let's assume the zip structure was PROJECT/product... \n",
                "        # If Kaggle unzips, we might have /kaggle/input/datasetname/product\n",
                "        # We need /kaggle/working/PROJECT/product\n",
                "        \n",
                "        src_product = found_product[0]\n",
                "        dest_product = WORK_DIR / 'product'\n",
                "        \n",
                "        print(f\"Found product folder at: {src_product}\")\n",
                "        print(f\"Copying to {dest_product}...\")\n",
                "        shutil.copytree(src_product, dest_product)\n",
                "        \n",
                "        # Also we need 'diary.md' and others if they exist at sibling level\n",
                "        src_root = src_product.parent\n",
                "        for item in src_root.iterdir():\n",
                "            if item.name != 'product' and item.is_file():\n",
                "                 shutil.copy(item, WORK_DIR / item.name)\n",
                "        print(\"Copy complete.\")\n",
                "        \n",
                "    else:\n",
                "        # Debug info\n",
                "        print(\"!!! ERROR: Could not find dataset !!!\")\n",
                "        print(\"Listing /kaggle/input content:\")\n",
                "        for p in KAGGLE_INPUT_DIR.rglob('*'):\n",
                "             if p.is_dir() and len(p.parts) < 6:\n",
                "                 print(p)\n",
                "        raise FileNotFoundError(\"Dataset not found! Did you add 'colab_all_kfold.zip' to the notebook inputs?\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 2. SETUP ENVIRONMENT & FIX PATHS ---\n",
                "os.chdir(WORK_DIR)\n",
                "print(f\"Current working directory: {os.getcwd()}\")\n",
                "\n",
                "ROOT = WORK_DIR\n",
                "SPLITS = ROOT / 'product/artifacts/splits'\n",
                "\n",
                "fixed = 0\n",
                "if SPLITS.exists():\n",
                "    for csv_file in SPLITS.glob('*.csv'):\n",
                "        text = csv_file.read_text()\n",
                "        if WIN_PREFIX in text:\n",
                "            text = text.replace(WIN_PREFIX, str(ROOT) + '/')\n",
                "            text = text.replace('\\\\', '/')\n",
                "            csv_file.write_text(text)\n",
                "            fixed += 1\n",
                "    print(f\"Fixed paths in {fixed} CSV files.\")\n",
                "else:\n",
                "    print(\"WARNING: splits directory not found. Something might be wrong with extraction.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 3. RUNNING ENGINE ---\n",
                "def run_kfold(dataset, models):\n",
                "    print(f\"\\n[{dataset.upper()}] Starting Runs...\")\n",
                "    RESULTS_DIR = ROOT / 'product/artifacts/runs' / dataset\n",
                "    RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
                "    \n",
                "    for model in models:\n",
                "        for fold in range(5):\n",
                "            run_id = f\"{dataset}_{model}_fold{fold}\"\n",
                "            summary_path = RESULTS_DIR / run_id / 'summary.json'\n",
                "            \n",
                "            if summary_path.exists():\n",
                "                print(f\"SKIP {run_id} (Already Done)\")\n",
                "                continue\n",
                "                \n",
                "            print(f\">>> RUNNING {run_id}\")\n",
                "            \n",
                "            # Base Params\n",
                "            args = ['--epochs', '30', '--batch_size', '32']\n",
                "            \n",
                "            # OVERRIDE: Dataset Specific Protocol\n",
                "            if dataset == 'pitt':\n",
                "                args += ['--weighted_loss', '--lr', '1e-5', '--dropout', '0.7', '--weight_decay', '0.1', '--unfreeze_at', '10']\n",
                "            elif dataset == 'italian_pd':\n",
                "                 args += ['--lr', '5e-5', '--dropout', '0.5']\n",
                "                \n",
                "            cmd = [sys.executable, '-u', 'product/training/train_unified.py', \n",
                "                   '--dataset', dataset, \n",
                "                   '--model_type', model, \n",
                "                   '--fold', str(fold)] + args\n",
                "                   \n",
                "            # Run and stream output\n",
                "            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
                "            for line in process.stdout:\n",
                "                print(line, end='')\n",
                "            \n",
                "            process.wait()\n",
                "            if process.returncode != 0:\n",
                "                print(f\"!!! ERROR in {run_id} !!!\")\n",
                "            else:\n",
                "                print(f\"--- Finished {run_id} ---\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 4. EXECUTE REMAINING EXPERIMENTS ---\n",
                "# 1. ESC-50: Only HybridNet (ResNet/MobileNet are complete)\n",
                "print(\"\\n--- STARTING ESC-50 ---\")\n",
                "run_kfold('esc50', ['hybrid'])\n",
                "\n",
                "# 2. EmoDB: All Models (Fresh start)\n",
                "print(\"\\n--- STARTING EMODB ---\")\n",
                "run_kfold('emodb', ['resnet50', 'mobilenetv2', 'hybrid'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 5. ZIP RESULTS ---\n",
                "output_zip = '/kaggle/working/kfold_final_results.zip'\n",
                "print(f\"Zipping results to {output_zip}...\")\n",
                "\n",
                "def zip_dir(path, ziph):\n",
                "    for root, dirs, files in os.walk(path):\n",
                "        for file in files:\n",
                "            ziph.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), os.path.join(path, '..')))\n",
                "\n",
                "with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
                "    zip_dir(ROOT / 'product/artifacts/runs', zipf)\n",
                "\n",
                "print(\"Done! Download kfold_final_results.zip from the Output tab.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
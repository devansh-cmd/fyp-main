{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1eb754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDIO_DIR      = C:\\FYP\\PROJECT\\product\\audio_preprocessing\\data\\ESC-50\\audio\n",
      "AUG_AUDIO_OUT  = C:\\FYP\\PROJECT\\product\\audio_preprocessing\\outputs\\augmented_audio\n",
      "AUG_SPEC_OUT   = C:\\FYP\\PROJECT\\product\\audio_preprocessing\\outputs\\augmented_spectrograms\n",
      "AUDIO_DIR exists?  True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# absolute root of your repo\n",
    "PROJECT_ROOT = Path(r\"C:\\FYP\\PROJECT\")\n",
    "\n",
    "# audio_preprocessing module root\n",
    "AUDIO_PREPROC_ROOT = PROJECT_ROOT / \"product\" / \"audio_preprocessing\"\n",
    "\n",
    "# dataset locations\n",
    "AUDIO_DIR = AUDIO_PREPROC_ROOT / \"data\" / \"ESC-50\" / \"audio\"\n",
    "\n",
    "# output locations\n",
    "AUG_AUDIO_OUT = AUDIO_PREPROC_ROOT / \"outputs\" / \"augmented_audio\"\n",
    "AUG_SPEC_OUT  = AUDIO_PREPROC_ROOT / \"outputs\" / \"augmented_spectrograms\"\n",
    "\n",
    "AUG_AUDIO_OUT.mkdir(parents=True, exist_ok=True)\n",
    "AUG_SPEC_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"AUDIO_DIR      =\", AUDIO_DIR)\n",
    "print(\"AUG_AUDIO_OUT  =\", AUG_AUDIO_OUT)\n",
    "print(\"AUG_SPEC_OUT   =\", AUG_SPEC_OUT)\n",
    "print(\"AUDIO_DIR exists? \", AUDIO_DIR.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777f8cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: C:\\FYP\\PROJECT\\product\\audio_preprocessing\\data\\ESC-50\\audio\\1-137-A-32.wav\n",
      "Waveform shape: (220500,)\n",
      "Sample rate: 44100\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf  # to write .wav files\n",
    "\n",
    "SAMPLE_FILE = \"1-137-A-32.wav\"  # <-- use something that definitely exists\n",
    "\n",
    "wav_path = AUDIO_DIR / SAMPLE_FILE\n",
    "y, sr = librosa.load(wav_path, sr=None)  # y = waveform (float32), sr = sample rate\n",
    "\n",
    "print(\"Loaded:\", wav_path)\n",
    "print(\"Waveform shape:\", y.shape)\n",
    "print(\"Sample rate:\", sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de88a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def augment_add_noise(y, noise_factor=0.02):\n",
    "    # white noise scaled to noise_factor * signal std\n",
    "    noise = np.random.randn(len(y))\n",
    "    augmented = y + noise_factor * np.std(y) * noise\n",
    "    return augmented.astype(np.float32)\n",
    "\n",
    "def augment_time_stretch(y, rate=0.9):\n",
    "    # rate < 1.0 = slower (longer clip), rate > 1.0 = faster (shorter clip)\n",
    "    stretched = librosa.effects.time_stretch(y, rate=rate)\n",
    "    return stretched.astype(np.float32)\n",
    "\n",
    "def augment_pitch_shift(y, sr, n_steps=2):\n",
    "    # n_steps = +2 means shift pitch up 2 semitones\n",
    "    shifted = librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n",
    "    return shifted.astype(np.float32)\n",
    "\n",
    "def augment_gain(y, gain_db=6.0):\n",
    "    # change volume in decibels\n",
    "    factor = 10 ** (gain_db / 20.0)\n",
    "    louder = y * factor\n",
    "    # clip safely so we don't blow up\n",
    "    louder = np.clip(louder, -1.0, 1.0)\n",
    "    return louder.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b3cd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: C:\\FYP\\PROJECT\\product\\audio_preprocessing\\outputs\\augmented_audio\\1-137-A-32_noise.wav\n",
      "Wrote: C:\\FYP\\PROJECT\\product\\audio_preprocessing\\outputs\\augmented_audio\\1-137-A-32_stretch0.9.wav\n",
      "Wrote: C:\\FYP\\PROJECT\\product\\audio_preprocessing\\outputs\\augmented_audio\\1-137-A-32_pitch+2.wav\n",
      "Wrote: C:\\FYP\\PROJECT\\product\\audio_preprocessing\\outputs\\augmented_audio\\1-137-A-32_gain+6db.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_name = SAMPLE_FILE.replace(\".wav\", \"\")\n",
    "variants = {}\n",
    "\n",
    "variants[f\"{base_name}_noise.wav\"] = augment_add_noise(y, noise_factor=0.02)\n",
    "variants[f\"{base_name}_stretch0.9.wav\"] = augment_time_stretch(y, rate=0.9)\n",
    "variants[f\"{base_name}_pitch+2.wav\"] = augment_pitch_shift(y, sr=sr, n_steps=+2)\n",
    "variants[f\"{base_name}_gain+6db.wav\"] = augment_gain(y, gain_db=6.0)\n",
    "\n",
    "for new_name, new_waveform in variants.items():\n",
    "    out_path = AUG_AUDIO_OUT / new_name\n",
    "    # IMPORTANT: when time-stretch happens, length changes; that's fine.\n",
    "    sf.write(out_path, new_waveform, sr)\n",
    "    print(\"Wrote:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a0c1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved augmented spectrogram → C:\\FYP\\PROJECT\\product\\audio_preprocessing\\outputs\\augmented_spectrograms\\1-137-A-32_noise.png\n",
      "Saved augmented spectrogram → C:\\FYP\\PROJECT\\product\\audio_preprocessing\\outputs\\augmented_spectrograms\\1-137-A-32_stretch0.9.png\n",
      "Saved augmented spectrogram → C:\\FYP\\PROJECT\\product\\audio_preprocessing\\outputs\\augmented_spectrograms\\1-137-A-32_pitch+2.png\n",
      "Saved augmented spectrogram → C:\\FYP\\PROJECT\\product\\audio_preprocessing\\outputs\\augmented_spectrograms\\1-137-A-32_gain+6db.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "def audio_to_mel_db(y, sr, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels\n",
    "    )\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    return S_db\n",
    "\n",
    "for new_name, new_waveform in variants.items():\n",
    "    # make mel\n",
    "    S_db = audio_to_mel_db(new_waveform, sr)\n",
    "\n",
    "    # plot mel\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    librosa.display.specshow(\n",
    "        S_db,\n",
    "        sr=sr,\n",
    "        hop_length=512,\n",
    "        x_axis='time',\n",
    "        y_axis='mel',\n",
    "        cmap='magma'\n",
    "    )\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f\"Mel spectrogram: {new_name}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # save PNG next to other augmented spectrograms\n",
    "    png_name = new_name.replace(\".wav\", \".png\")\n",
    "    out_path = AUG_SPEC_OUT / png_name\n",
    "    plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Saved augmented spectrogram →\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
